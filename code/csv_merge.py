import pandas as pd
import numpy as np
import open3d as o3d
import tkinter as tk
from tkinter import filedialog
import os
import copy
from collections import defaultdict
from sklearn.cluster import DBSCAN

# =============================================================================
# ì„¹ì…˜ 0: ìˆ˜ë™ ì •ë ¬ ë° ì‹œê°í™” ë„ìš°ë¯¸ (ìˆ˜ì • ì—†ìŒ)
# =============================================================================
def manual_tweak_registration(source_pcd, target_pcd, T_init, t_step=10.0, r_step_deg=1.0):
    """
    [ë‹¨ìˆœí™” ë²„ì „] Sourceì™€ Targetì„ ê°ê° ë‹¨ìƒ‰ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ìˆ˜ë™ ë¯¸ì„¸ì¡°ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    source_pcd: ì›€ì§ì¼ Open3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°ì²´
    target_pcd: ê¸°ì¤€ì´ ë˜ëŠ” Open3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°ì²´
    """
    # --- â–¼â–¼â–¼ ìƒ‰ìƒ ë¡œì§ ë‹¨ìˆœí™” â–¼â–¼â–¼ ---
    #ê³ ì •ëœ ìƒ‰ìƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    tgt = o3d.geometry.PointCloud(target_pcd)
    src0 = o3d.geometry.PointCloud(source_pcd) 
    D = {"mat": np.eye(4)}
    # --- â–²â–²â–² ë¡œì§ ë‹¨ìˆœí™” ì™„ë£Œ â–²â–²â–² ---

    def rot(axis, deg):
        th = np.deg2rad(deg); c, s = np.cos(th), np.sin(th)
        if axis == 'x': R = np.array([[1,0,0],[0,c,-s],[0,s,c]])
        elif axis == 'y': R = np.array([[c,0,s],[0,1,0],[-s,0,c]])
        else: R = np.array([[c,-s,0],[s,c,0],[0,0,1]])
        M = np.eye(4); M[:3,:3] = R; return M
    def trans(dx,dy,dz):
        M = np.eye(4); M[:3,3] = [dx,dy,dz]; return M
    def apply(M): D["mat"] = M @ D["mat"]

    def redraw(vis):
        vis.clear_geometries()
        
        # Target í¬ì¸íŠ¸ í´ë¼ìš°ë“œëŠ” íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œ
        tgt_show = o3d.geometry.PointCloud(tgt)
        tgt_show.paint_uniform_color([0.7, 0.7, 0.7])
        vis.add_geometry(tgt_show)
        
        # Source í¬ì¸íŠ¸ í´ë¼ìš°ë“œëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ
        src_show = o3d.geometry.PointCloud(src0)
        src_show.transform(D["mat"] @ T_init)
        src_show.paint_uniform_color([1, 0, 0]) # <- ë‹¨ìƒ‰ìœ¼ë¡œ ì¹ í•˜ëŠ” ë¶€ë¶„!
        vis.add_geometry(src_show)
        
        return False

    vis = o3d.visualization.VisualizerWithKeyCallback()
    # ì°½ ì œëª©ë„ ê°„ê²°í•˜ê²Œ ë³€ê²½
    vis.create_window("Manual Tweak (WASDRF, IJKLOU) | Z=Save, Close=Cancel")
    redraw(vis)
    
    # (í‚¤ ì½œë°± ë¶€ë¶„ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    vis.register_key_callback(ord('A'), lambda v: (apply(trans(-t_step,0,0)), redraw(v))[1])
    vis.register_key_callback(ord('D'), lambda v: (apply(trans(+t_step,0,0)), redraw(v))[1])
    vis.register_key_callback(ord('W'), lambda v: (apply(trans(0,+t_step,0)), redraw(v))[1])
    vis.register_key_callback(ord('S'), lambda v: (apply(trans(0,-t_step,0)), redraw(v))[1])
    vis.register_key_callback(ord('R'), lambda v: (apply(trans(0,0,+t_step)), redraw(v))[1])
    vis.register_key_callback(ord('F'), lambda v: (apply(trans(0,0,-t_step)), redraw(v))[1])
    vis.register_key_callback(ord('I'), lambda v: (apply(rot('x',-r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('K'), lambda v: (apply(rot('x',+r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('J'), lambda v: (apply(rot('y',-r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('L'), lambda v: (apply(rot('y',+r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('U'), lambda v: (apply(rot('z',-r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('O'), lambda v: (apply(rot('z',+r_step_deg)), redraw(v))[1])
    vis.register_key_callback(32, lambda v: (D.update(mat=np.eye(4)), redraw(v))[1])
    confirmed = {"ok": False}
    vis.register_key_callback(ord('Z'), lambda v: (confirmed.update(ok=True), v.close())[1])
    
    vis.run(); vis.destroy_window()
    return (D["mat"] @ T_init)

# =============================================================================
# ì„¹ì…˜ 1: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ê¸°ì¡´ í•¨ìˆ˜ë“¤, ìˆ˜ì • ì—†ìŒ)
# =============================================================================
def preprocess_pcd(pcd, fpfh_size):
    pcd_down = pcd.voxel_down_sample(fpfh_size)
    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=fpfh_size * 2, max_nn=30))
    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
        pcd_down, o3d.geometry.KDTreeSearchParamHybrid(radius=fpfh_size * 5, max_nn=100))
    return pcd_down, pcd_fpfh

def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, fpfh_size):
    distance_threshold = fpfh_size * 1.5
    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
        source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold,
        o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 3,
        [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.95),
         o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],
        o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.9999))
    return result

def refine_registration(source, target, initial_transform, fpfh_size):
    distance_threshold = fpfh_size * 0.4
    result = o3d.pipelines.registration.registration_icp(
        source, target, distance_threshold, initial_transform,
        o3d.pipelines.registration.TransformationEstimationPointToPlane())
    return result

# =============================================================================
# ì„¹ì…˜ 2: ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (â­ï¸â­ï¸â­ï¸ ìƒˆë¡œ ì¶”ê°€/ìˆ˜ì •ëœ ë¶€ë¶„ â­ï¸â­ï¸â­ï¸)
# =============================================================================
def group_blind_spots_with_virtual_scanners(df, voxel_size):
    """
    DBSCANì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ê°ì§€ëŒ€ í¬ì¸íŠ¸ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•˜ê³ , ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•´
    ê°€ìƒ ìŠ¤ìºë„ˆë¥¼ ë°°ì¹˜í•˜ì—¬ ìƒˆë¡œìš´ (dist, az, el) ê·¸ë£¹ì„ ìƒì„±í•©ë‹ˆë‹¤. (ìˆ˜ì •ëœ ë²„ì „)
    """
    print("\n[ìƒˆ ì‘ì—…] ê°€ìƒ ìŠ¤ìºë„ˆ ê¸°ë°˜ ì‚¬ê°ì§€ëŒ€ ê·¸ë£¹í•‘ ì‹œì‘...")

    blind_spot_df = df[df['status'] == 'blind_spot'].copy()
    if blind_spot_df.empty:
        print("-> ë¶„ì„í•  ì‚¬ê°ì§€ëŒ€ê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return df

    xyz_points = blind_spot_df[['x', 'y', 'z']].values

    dbscan = DBSCAN(eps=voxel_size * 3, min_samples=20)
    cluster_labels = dbscan.fit_predict(xyz_points)
    blind_spot_df['cluster_id'] = cluster_labels

    num_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)
    num_noise = np.sum(cluster_labels == -1)
    print(f"-> DBSCAN ë¶„ì„ ì™„ë£Œ: {num_clusters}ê°œì˜ í´ëŸ¬ìŠ¤í„°ì™€ {num_noise}ê°œì˜ ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    if num_clusters == 0:
        print("-> ìœ ì˜ë¯¸í•œ í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        # cluster_idë§Œ ì¶”ê°€ëœ dfë¥¼ ë°˜í™˜í•˜ê¸° ìœ„í•´ join ì‚¬ìš©
        return df.join(blind_spot_df[['cluster_id']])

    print("-> ê° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ì— ê°€ìƒ ìŠ¤ìºë„ˆë¥¼ ë°°ì¹˜í•˜ê³  ê·¸ë£¹í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    blind_spot_df['virtual_dist'] = np.nan
    blind_spot_df['virtual_az'] = np.nan
    blind_spot_df['virtual_el'] = np.nan

    for cluster_id in range(num_clusters):
        cluster_mask = blind_spot_df['cluster_id'] == cluster_id
        current_cluster_points = blind_spot_df.loc[cluster_mask, ['x', 'y', 'z']].values
        
        virtual_scanner_pos = np.mean(current_cluster_points, axis=0)
        vectors = current_cluster_points - virtual_scanner_pos
        
        dist = np.linalg.norm(vectors, axis=1)
        az = np.degrees(np.arctan2(vectors[:, 0], vectors[:, 1]))
        el = np.degrees(np.arcsin(np.clip(vectors[:, 2] / (dist + 1e-9), -1.0, 1.0)))
        
        blind_spot_df.loc[cluster_mask, 'virtual_dist'] = dist
        blind_spot_df.loc[cluster_mask, 'virtual_az'] = az
        blind_spot_df.loc[cluster_mask, 'virtual_el'] = el
        print(f"  -> í´ëŸ¬ìŠ¤í„° {cluster_id} ì²˜ë¦¬ ì™„ë£Œ. ({len(current_cluster_points)}ê°œ í¬ì¸íŠ¸)")

    # â­ï¸â­ï¸â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„: df.update() ëŒ€ì‹  ë” ì•ˆì •ì ì¸ df.join() ì‚¬ìš© â­ï¸â­ï¸â­ï¸
    # ì—…ë°ì´íŠ¸í•  ì—´ ëª©ë¡
    update_cols = ['cluster_id', 'virtual_dist', 'virtual_az', 'virtual_el']
    # blind_spot_dfì˜ ê³„ì‚° ê²°ê³¼ë¥¼ ì›ë³¸ dfì˜ ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³‘í•©
    result_df = df.join(blind_spot_df[update_cols])
    
    print("âœ… ì‚¬ê°ì§€ëŒ€ ê·¸ë£¹í•‘ ì™„ë£Œ.")
    return result_df
def load_all_scans_to_dataframe(file_paths):
    """
    ëª¨ë“  CSV íŒŒì¼ì„ í•˜ë‚˜ì˜ Pandas DataFrameìœ¼ë¡œ í†µí•© ë¡œë”©í•©ë‹ˆë‹¤.
    ì´ë•Œ, ìŠ¤ìºë„ˆì˜ í¸ì‹¬ íšŒì „ ì˜¤í”„ì…‹ì„ ë³´ì •í•˜ì—¬ ì¢Œí‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    all_dfs = []
    scanner_offset = 58.2  # í¸ì‹¬ íšŒì „ ì˜¤í”„ì…‹ ê°’ (mm)

    for i, path in enumerate(file_paths):
        try:
            df = pd.read_csv(path, header=None, names=['dist', 'az', 'el'])
            df['scanner_id'] = i  # ì–´ë–¤ ìŠ¤ìºë„ˆì—ì„œ ì™”ëŠ”ì§€ ID ë¶€ì—¬

            # az, el ìˆœìœ¼ë¡œ ì •ë ¬ (ë°ì´í„° ì²˜ë¦¬ ì¼ê´€ì„± ìœ ì§€)
            df_sorted = df.sort_values(by=['az', 'el']).copy()

            # ì •ë ¬ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 3D ì¢Œí‘œ ê³„ì‚°
            dist = df_sorted['dist'].values
            az_rad = np.radians(df_sorted['az'].values)
            el_rad = np.radians(df_sorted['el'].values + 90)

            # 1. ì¸¡ì • í—¤ë“œë¡œë¶€í„°ì˜ ìƒëŒ€ ì¢Œí‘œ
            x_relative = dist * np.cos(el_rad) * np.sin(az_rad)
            y_relative = dist * np.cos(el_rad) * np.cos(az_rad)
            z_relative = dist * np.sin(el_rad)

            # 2. Azimuth íšŒì „ì— ë”°ë¥¸ ì¸¡ì • í—¤ë“œì˜ ìœ„ì¹˜ (ì˜¤í”„ì…‹ ë³´ì •)
            scanner_x = scanner_offset * np.cos(az_rad)
            scanner_y = scanner_offset * np.sin(az_rad)
            # z_offsetì€ 0ìœ¼ë¡œ ê°€ì •

            # 3. ìµœì¢… ì¢Œí‘œ = ì¸¡ì • í—¤ë“œ ìœ„ì¹˜ + ìƒëŒ€ ì¢Œí‘œ
            df_sorted['x'] = + scanner_x + x_relative
            df_sorted['y'] = + scanner_y - y_relative
            df_sorted['z'] = z_relative
            
            all_dfs.append(df_sorted)
            print(f"-> '{os.path.basename(path)}' ë¡œë“œ ë° í¸ì‹¬ ë³´ì • ì™„ë£Œ, ìŠ¤ìºë„ˆ ID: {i}")

        except Exception as e:
            print(f"ì˜¤ë¥˜: '{path}' íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            
    # ëª¨ë“  DataFrameì„ í•˜ë‚˜ë¡œ í•©ì¹¨
    return pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()

def apply_transforms_to_dataframe(df, transforms):
    """ê³„ì‚°ëœ ë³€í™˜ í–‰ë ¬ì„ DataFrameì˜ ê° í¬ì¸íŠ¸ì— ì ìš©í•©ë‹ˆë‹¤."""
    df_transformed = df.copy()
    for scanner_id, transform in enumerate(transforms):
        if scanner_id == 0: continue
        indices = df_transformed[df_transformed['scanner_id'] == scanner_id].index
        points = df_transformed.loc[indices, ['x', 'y', 'z']].values
        points_h = np.hstack((points, np.ones((len(points), 1))))
        transformed_points_h = (transform @ points_h.T).T
        df_transformed.loc[indices, ['x', 'y', 'z']] = transformed_points_h[:, :3]
    print("-> ëª¨ë“  í¬ì¸íŠ¸ì— ë³€í™˜ í–‰ë ¬ ì ìš© ì™„ë£Œ.")
    return df_transformed

def find_blind_spots(df, voxel_size, reference_scanner_id=0):
    """
    ì •í•©ëœ ì „ì²´ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì—ì„œ ê¸°ì¤€ ìŠ¤ìºë„ˆì˜ ì‚¬ê°ì§€ëŒ€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

    Args:
        df (pd.DataFrame): ë³€í™˜ì´ ëª¨ë‘ ì ìš©ëœ ì „ì²´ í¬ì¸íŠ¸ ë°ì´í„°.
        voxel_size (float): ê³µê°„ì„ ë‚˜ëˆŒ Voxelì˜ í¬ê¸°.
        reference_scanner_id (int): ê¸°ì¤€ì´ ë  ìŠ¤ìºë„ˆì˜ ID (ê¸°ë³¸ê°’: 0).

    Returns:
        o3d.geometry.PointCloud: ì‚¬ê°ì§€ëŒ€ê°€ ì‹œê°í™”ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°ì²´.
                                 (ì´ˆë¡ìƒ‰: ê¸°ì¤€ ìŠ¤ìºë„ˆ ì˜ì—­, ë¹¨ê°„ìƒ‰: ì‚¬ê°ì§€ëŒ€)
    """
    print(f"\n[ìƒˆ ì‘ì—…] ê¸°ì¤€ ìŠ¤ìºë„ˆ({reference_scanner_id})ì˜ ì‚¬ê°ì§€ëŒ€ ë¶„ì„ ì‹œì‘...")

    # 1. ëª¨ë“  ì ì— ëŒ€í•´ Voxel ì¸ë±ìŠ¤ ë¶€ì—¬
    df['voxel_index'] = [tuple(idx) for idx in np.floor(df[['x', 'y', 'z']].values / voxel_size).astype(int)]

    # 2. ì „ì²´ ê³µê°„ì„ ì°¨ì§€í•˜ëŠ” Voxelê³¼ ê¸°ì¤€ ìŠ¤ìºë„ˆê°€ ì°¨ì§€í•˜ëŠ” Voxel ê³„ì‚°
    all_occupied_voxels = set(df['voxel_index'])
    print(f"-> ì´ {len(all_occupied_voxels)}ê°œì˜ Voxelì— í¬ì¸íŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
    
    ref_scanner_voxels = set(df[df['scanner_id'] == reference_scanner_id]['voxel_index'])
    print(f"-> ê¸°ì¤€ ìŠ¤ìºë„ˆ({reference_scanner_id})ëŠ” ì´ ì¤‘ {len(ref_scanner_voxels)}ê°œì˜ Voxelì„ í¬í•¨í•©ë‹ˆë‹¤.")

    # 3. ì‚¬ê°ì§€ëŒ€ Voxel ê³„ì‚° (ì°¨ì§‘í•©)
    blind_spot_voxels = all_occupied_voxels - ref_scanner_voxels
    print(f"-> ê³„ì‚°ëœ ì‚¬ê°ì§€ëŒ€ Voxel ê°œìˆ˜: {len(blind_spot_voxels)}")

    # 4. ì‹œê°í™”ë¥¼ ìœ„í•´ ê° í¬ì¸íŠ¸ì— ìƒ‰ìƒ ì •ë³´ ë¶€ì—¬
    # Voxel ì¸ë±ìŠ¤ë¥¼ í‚¤ë¡œ, ìƒíƒœ('covered' ë˜ëŠ” 'blind_spot')ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
    voxel_status_map = {voxel: 'covered' for voxel in ref_scanner_voxels}
    voxel_status_map.update({voxel: 'blind_spot' for voxel in blind_spot_voxels})

    # ëª¨ë“  í¬ì¸íŠ¸ì— Voxel ìƒíƒœë¥¼ ë§¤í•‘
    df['status'] = df['voxel_index'].map(voxel_status_map)

    # ìµœì¢… í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
    pcd_final = o3d.geometry.PointCloud()
    pcd_final.points = o3d.utility.Vector3dVector(df[['x', 'y', 'z']].values)

    # ìƒíƒœì— ë”°ë¼ ìƒ‰ìƒ ì§€ì •
    point_colors = np.zeros_like(df[['x', 'y', 'z']].values)
    
    # ê¸°ì¤€ ìŠ¤ìºë„ˆê°€ ì»¤ë²„í•˜ëŠ” ì˜ì—­ì˜ í¬ì¸íŠ¸ (ì´ˆë¡ìƒ‰)
    covered_mask = (df['status'] == 'covered')
    point_colors[covered_mask] = [0.1, 0.8, 0.2]  # Green

    # ì‚¬ê°ì§€ëŒ€ ì˜ì—­ì˜ í¬ì¸íŠ¸ (ë¹¨ê°„ìƒ‰)
    blind_spot_mask = (df['status'] == 'blind_spot')
    point_colors[blind_spot_mask] = [1.0, 0.2, 0.1]  # Red
    
    pcd_final.colors = o3d.utility.Vector3dVector(point_colors)
    print("-> ì‹œê°í™” ì¤€ë¹„ ì™„ë£Œ. ì´ˆë¡ìƒ‰: ê¸°ì¤€ ìŠ¤ìºë„ˆ, ë¹¨ê°„ìƒ‰: ì‚¬ê°ì§€ëŒ€")

    return pcd_final,df
class StatisticalOutlierRemover:
    """
    Open3Dì˜ í†µê³„ì  ì´ìƒì¹˜ ì œê±°(statistical outlier removal) ê¸°ëŠ¥ì„
    ìº¡ìŠí™”í•œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

    ì´ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ í•„í„°ë§ íŒŒë¼ë¯¸í„°ë¥¼ ê°ì²´ì— ì €ì¥í•´ë‘ê³ 
    ì—¬ëŸ¬ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì— ì¼ê´€ë˜ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    def __init__(self, nb_neighbors, std_ratio):
        """
        í•„í„° ê°ì²´ë¥¼ ì´ˆê¸°í™”í•˜ê³  íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

        Args:
            nb_neighbors (int): ê° ì ì˜ í‰ê·  ê±°ë¦¬ë¥¼ ê³„ì‚°í•  ë•Œ ê³ ë ¤í•  ì´ì›ƒ ì ì˜ ìˆ˜.
            std_ratio (float): ì´ìƒì¹˜ë¡œ ê°„ì£¼í•  í‘œì¤€ í¸ì°¨ì˜ ë°°ìˆ˜.
                               ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ë§ì€ ì ì„ ì´ìƒì¹˜ë¡œ ì œê±°í•©ë‹ˆë‹¤.
        """
        self.nb_neighbors = nb_neighbors
        self.std_ratio = std_ratio
        print(f"í•„í„° ìƒì„±ë¨: ì´ì›ƒ ìˆ˜={self.nb_neighbors}, í‘œì¤€í¸ì°¨ ë¹„ìœ¨={self.std_ratio}")

    def filter(self, pcd):
        """
        ì…ë ¥ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì— ëŒ€í•´ í†µê³„ì  ì´ìƒì¹˜ ì œê±°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            pcd (o3d.geometry.PointCloud): í•„í„°ë§ì„ ì ìš©í•  í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°ì²´.

        Returns:
            tuple: (filtered_pcd, inlier_indices)
                - filtered_pcd (o3d.geometry.PointCloud): ì´ìƒì¹˜ê°€ ì œê±°ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ.
                - inlier_indices (o3d.utility.IntVector): ì›ë³¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì—ì„œ ì‚´ì•„ë‚¨ì€ ì (inlier)ë“¤ì˜ ì¸ë±ìŠ¤.
        """
        if not isinstance(pcd, o3d.geometry.PointCloud):
            raise TypeError("ì…ë ¥ê°’ì€ open3d.geometry.PointCloud ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        print("ì´ìƒì¹˜ ì œê±° í•„í„°ë§ ì‹œì‘...")
        # remove_statistical_outlier í•¨ìˆ˜ëŠ” (í¬ì¸íŠ¸í´ë¼ìš°ë“œ, ì¸ë±ìŠ¤) íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        filtered_pcd, ind = pcd.remove_statistical_outlier(
            nb_neighbors=self.nb_neighbors,
            std_ratio=self.std_ratio
        )
        print(f"í•„í„°ë§ ì™„ë£Œ: ì›ë³¸ {len(pcd.points)}ê°œ -> ì œê±° í›„ {len(filtered_pcd.points)}ê°œ")
        return filtered_pcd, ind
# =============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€ (â­ï¸â­ï¸â­ï¸ ì´ìƒì¹˜ ì œê±° ë‹¨ê³„ ì¶”ê°€ â­ï¸â­ï¸â­ï¸)
# =============================================================================
if __name__ == "__main__":
    root = tk.Tk(); root.withdraw()
    print("ë¶„ì„í•  CSV íŒŒì¼ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì„ íƒí•˜ì„¸ìš” (2ê°œ ì´ìƒ)")
    file_paths = filedialog.askopenfilenames(title="CSV íŒŒì¼ ì„ íƒ (ê¸°ì¤€ íŒŒì¼ ë¨¼ì €)", filetypes=[("CSV Files", "*.csv")])

    if len(file_paths) < 2:
        print("íŒŒì¼ì´ 2ê°œ ë¯¸ë§Œ ì„ íƒë˜ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        # --- 1ë‹¨ê³„: ëª¨ë“  CSVë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë¡œë”© ---
        print("\n[1/5] CSV íŒŒì¼ ë¡œë”© ë° í†µí•©...")
        master_df = load_all_scans_to_dataframe(file_paths)
        if master_df.empty: exit()

        # --- â­ï¸ 2ë‹¨ê³„: ê° ìŠ¤ìº”ì— ëŒ€í•´ ì´ìƒì¹˜ ì œê±° ìˆ˜í–‰ (ìƒˆë¡œ ì¶”ê°€ëœ ë‹¨ê³„) â­ï¸ ---
        print("\n[2/5] í†µê³„ì  ì´ìƒì¹˜ ì œê±° ì‹œì‘...")
        # 1. ì´ìƒì¹˜ ì œê±° í•„í„° ê°ì²´ ìƒì„± (íŒŒë¼ë¯¸í„°ëŠ” ë°ì´í„°ì— ë§ê²Œ ì¡°ì •)
        sor_filter = StatisticalOutlierRemover(nb_neighbors=100, std_ratio=2.0)
        
        cleaned_dfs = []
        for i in range(len(file_paths)):
            scan_df = master_df[master_df['scanner_id'] == i]
            
            # DataFrameì„ Open3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ë³€í™˜
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(scan_df[['x', 'y', 'z']].values)
            
            # í•„í„° ì ìš©
            print(f"-> ìŠ¤ìºë„ˆ ID {i} í•„í„°ë§ ì¤‘...")
            filtered_pcd, inlier_indices = sor_filter.filter(pcd)
            
            # ì‚´ì•„ë‚¨ì€ ì¸ë±ìŠ¤(inlier_indices)ë¥¼ ì‚¬ìš©í•´ ì›ë³¸ DataFrame í•„í„°ë§
            # np.asarrayë¥¼ í†µí•´ o3d.utility.IntVectorë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
            cleaned_scan_df = scan_df.iloc[np.asarray(inlier_indices)]
            cleaned_dfs.append(cleaned_scan_df)

        # ê¹¨ë—í•´ì§„ DataFrameë“¤ì„ ë‹¤ì‹œ í•˜ë‚˜ë¡œ í•©ì¹¨
        master_df_cleaned = pd.concat(cleaned_dfs, ignore_index=True)
        print("âœ… ëª¨ë“  ìŠ¤ìº”ì˜ ì´ìƒì¹˜ ì œê±° ì™„ë£Œ.")


        # --- 3ë‹¨ê³„: ìë™ ì •í•©ì„ ìœ„í•œ ë³€í™˜ í–‰ë ¬ ê³„ì‚° (ê¸°ì¡´ 2ë‹¨ê³„) ---
        # â­ï¸ ì´ì œë¶€í„°ëŠ” ê¹¨ë—í•´ì§„ master_df_cleanedë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        print("\n[3/5] ì •í•© ë³€í™˜ í–‰ë ¬ ê³„ì‚° ì‹œì‘...")
        voxel_size = 300.0
        fpfh_size= 30
        
        pcds_for_reg = [o3d.geometry.PointCloud(o3d.utility.Vector3dVector(
            master_df_cleaned[master_df_cleaned['scanner_id'] == i][['x', 'y', 'z']].values
        )) for i in range(len(file_paths))]

        final_transforms = [np.identity(4)]
        target_pcd_merged = copy.deepcopy(pcds_for_reg[0])

        for i in range(1, len(pcds_for_reg)):
            source_pcd = pcds_for_reg[i]
            print(f"\n-> ìŠ¤ìº” {i} ('{os.path.basename(file_paths[i])}') ì •í•© ì¤‘...")
            
            source_down, source_fpfh = preprocess_pcd(source_pcd, fpfh_size)
            target_down, target_fpfh = preprocess_pcd(target_pcd_merged, fpfh_size)

            ransac_result = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, fpfh_size)
            
            print("\nğŸ‘€ RANSAC ê²°ê³¼ ê¸°ë°˜ ìˆ˜ë™ ë¯¸ì„¸ì¡°ì •: í‚¤ë³´ë“œë¡œ ì¡°ì • í›„ 'Z'ë¡œ í™•ì •!")
            
            # â­ï¸ current_source_dfë„ ê¹¨ë—í•œ ë°ì´í„°í”„ë ˆì„ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            current_source_df = master_df_cleaned[master_df_cleaned['scanner_id'] == i]
            
            T_tweaked = manual_tweak_registration( # í•¨ìˆ˜ ì´ë¦„ ë³€ê²½
                source_pcd, 
                target_pcd_merged, 
                ransac_result.transformation
            )
            
            target_pcd_merged.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=fpfh_size * 2, max_nn=30))
            icp_result = refine_registration(source_pcd, target_pcd_merged, T_tweaked, fpfh_size)
            
            final_transforms.append(icp_result.transformation)
            
            source_pcd.transform(icp_result.transformation)
            target_pcd_merged += source_pcd
        print("âœ… ëª¨ë“  ë³€í™˜ í–‰ë ¬ ê³„ì‚° ì™„ë£Œ.")

        # --- 3.5ë‹¨ê³„ -> 4ë‹¨ê³„: ë³€í™˜ í–‰ë ¬ ì ìš© ---
        print("\n[4/5] ë³€í™˜ í–‰ë ¬ ì ìš©...")
        # â­ï¸ ë³€í™˜ í–‰ë ¬ì€ ê¹¨ë—í•œ ë°ì´í„°í”„ë ˆì„ì— ì ìš©í•©ë‹ˆë‹¤.
        transformed_df = apply_transforms_to_dataframe(master_df_cleaned, final_transforms)

        # --- 5ë‹¨ê³„: ì‚¬ê°ì§€ëŒ€ ë¶„ì„, ê·¸ë£¹í•‘ ë° ì‹œê°í™” ---
        print("\n[5/5] ì‚¬ê°ì§€ëŒ€ ë¶„ì„ ë° ê·¸ë£¹í•‘ ì‹œì‘...")
        
        # 1. ì‚¬ê°ì§€ëŒ€ ë¶„ì„ (ì´ˆë¡/ë¹¨ê°• ì‹œê°í™”)
        # ì´ì œ í•¨ìˆ˜ê°€ (pcd, df) íŠœí”Œì„ ë°˜í™˜
        pcd_with_blind_spots, transformed_df_with_status = find_blind_spots(
            transformed_df, voxel_size, reference_scanner_id=0
        )

        print("-> 1ì°¨ ê²°ê³¼: ì‚¬ê°ì§€ëŒ€ ë¶„ì„ ê²°ê³¼ (ì´ˆë¡: ê¸°ì¤€ ìŠ¤ìºë„ˆ, ë¹¨ê°•: ì‚¬ê°ì§€ëŒ€)")
        o3d.visualization.draw_geometries(
            [pcd_with_blind_spots],
            window_name="1. ì‚¬ê°ì§€ëŒ€ ë¶„ì„ ê²°ê³¼"
        )

        # 2. ê°€ìƒ ìŠ¤ìºë„ˆ ê¸°ë°˜ ê·¸ë£¹í•‘ ìˆ˜í–‰
        final_df = group_blind_spots_with_virtual_scanners(
            transformed_df_with_status, voxel_size
        )

        # 3. ê·¸ë£¹í•‘ ê²°ê³¼ ì‹œê°í™” (í´ëŸ¬ìŠ¤í„°ë³„ ìƒ‰ìƒ)
        print("-> 2ì°¨ ê²°ê³¼: í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ ê·¸ë£¹í•‘ ê²°ê³¼ ì‹œê°í™”")
        
        pcd_clustered = o3d.geometry.PointCloud()
        pcd_clustered.points = o3d.utility.Vector3dVector(final_df[['x', 'y', 'z']].values)
        
        # ìƒ‰ìƒ ì¤€ë¹„
        colors = np.zeros_like(final_df[['x', 'y', 'z']].values)
        
        # ê¸°ì¤€ ìŠ¤ìºë„ˆê°€ ë³¸ ì ë“¤ì€ íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œ
        covered_mask = final_df['status'] == 'covered'
        colors[covered_mask] = [0.7, 0.7, 0.7]

        # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ëœë¤ ìƒ‰ìƒ ì§€ì •
        cluster_ids = final_df['cluster_id'].dropna().unique()
        cluster_ids = cluster_ids[cluster_ids != -1] # ë…¸ì´ì¦ˆ(-1) ì œì™¸
        
        palette = np.random.rand(len(cluster_ids), 3)

        for i, cid in enumerate(cluster_ids):
            cluster_mask = final_df['cluster_id'] == cid
            colors[cluster_mask] = palette[i]
            
        # ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ëŠ” ê²€ì€ìƒ‰ìœ¼ë¡œ í‘œì‹œ
        noise_mask = final_df['cluster_id'] == -1
        colors[noise_mask] = [0, 0, 0]

        pcd_clustered.colors = o3d.utility.Vector3dVector(colors)

        o3d.visualization.draw_geometries(
            [pcd_clustered],
            window_name="2. ê°€ìƒ ìŠ¤ìºë„ˆ ê·¸ë£¹í•‘ ê²°ê³¼ (ìƒ‰ìƒ=í´ëŸ¬ìŠ¤í„°)"
        )

        # ìµœì¢… ë°ì´í„°í”„ë ˆì„ì„ CSVë¡œ ì €ì¥ (ì˜µì…˜)
        output_dir = "final_grouped_results"
        if not os.path.exists(output_dir): os.makedirs(output_dir)
        output_filename = os.path.join(output_dir, "grouped_blind_spot_data.csv")
        final_df.to_csv(output_filename, index=False, encoding='utf-8-sig')
        print(f"-> ìµœì¢… ê·¸ë£¹í•‘ ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: '{output_filename}'")
        
        print("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")