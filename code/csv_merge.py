import pandas as pd
import numpy as np
import open3d as o3d
import tkinter as tk
from tkinter import filedialog
import os
import copy
from collections import defaultdict

# =============================================================================
# ì„¹ì…˜ 0: ìˆ˜ë™ ì •ë ¬ ë° ì‹œê°í™” ë„ìš°ë¯¸ (ìˆ˜ì • ì—†ìŒ)
# =============================================================================
def manual_tweak_registration(source_pcd, target_pcd, T_init, t_step=10.0, r_step_deg=1.0):
    """
    [ë‹¨ìˆœí™” ë²„ì „] Sourceì™€ Targetì„ ê°ê° ë‹¨ìƒ‰ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ìˆ˜ë™ ë¯¸ì„¸ì¡°ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    source_pcd: ì›€ì§ì¼ Open3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°ì²´
    target_pcd: ê¸°ì¤€ì´ ë˜ëŠ” Open3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°ì²´
    """
    # --- â–¼â–¼â–¼ ìƒ‰ìƒ ë¡œì§ ë‹¨ìˆœí™” â–¼â–¼â–¼ ---
    #ê³ ì •ëœ ìƒ‰ìƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    tgt = o3d.geometry.PointCloud(target_pcd)
    src0 = o3d.geometry.PointCloud(source_pcd) 
    D = {"mat": np.eye(4)}
    # --- â–²â–²â–² ë¡œì§ ë‹¨ìˆœí™” ì™„ë£Œ â–²â–²â–² ---

    def rot(axis, deg):
        th = np.deg2rad(deg); c, s = np.cos(th), np.sin(th)
        if axis == 'x': R = np.array([[1,0,0],[0,c,-s],[0,s,c]])
        elif axis == 'y': R = np.array([[c,0,s],[0,1,0],[-s,0,c]])
        else: R = np.array([[c,-s,0],[s,c,0],[0,0,1]])
        M = np.eye(4); M[:3,:3] = R; return M
    def trans(dx,dy,dz):
        M = np.eye(4); M[:3,3] = [dx,dy,dz]; return M
    def apply(M): D["mat"] = M @ D["mat"]

    def redraw(vis):
        vis.clear_geometries()
        
        # Target í¬ì¸íŠ¸ í´ë¼ìš°ë“œëŠ” íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œ
        tgt_show = o3d.geometry.PointCloud(tgt)
        tgt_show.paint_uniform_color([0.7, 0.7, 0.7])
        vis.add_geometry(tgt_show)
        
        # Source í¬ì¸íŠ¸ í´ë¼ìš°ë“œëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ
        src_show = o3d.geometry.PointCloud(src0)
        src_show.transform(D["mat"] @ T_init)
        src_show.paint_uniform_color([1, 0, 0]) # <- ë‹¨ìƒ‰ìœ¼ë¡œ ì¹ í•˜ëŠ” ë¶€ë¶„!
        vis.add_geometry(src_show)
        
        return False

    vis = o3d.visualization.VisualizerWithKeyCallback()
    # ì°½ ì œëª©ë„ ê°„ê²°í•˜ê²Œ ë³€ê²½
    vis.create_window("Manual Tweak (WASDRF, IJKLOU) | Z=Save, Close=Cancel")
    redraw(vis)
    
    # (í‚¤ ì½œë°± ë¶€ë¶„ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    vis.register_key_callback(ord('A'), lambda v: (apply(trans(-t_step,0,0)), redraw(v))[1])
    vis.register_key_callback(ord('D'), lambda v: (apply(trans(+t_step,0,0)), redraw(v))[1])
    vis.register_key_callback(ord('W'), lambda v: (apply(trans(0,+t_step,0)), redraw(v))[1])
    vis.register_key_callback(ord('S'), lambda v: (apply(trans(0,-t_step,0)), redraw(v))[1])
    vis.register_key_callback(ord('R'), lambda v: (apply(trans(0,0,+t_step)), redraw(v))[1])
    vis.register_key_callback(ord('F'), lambda v: (apply(trans(0,0,-t_step)), redraw(v))[1])
    vis.register_key_callback(ord('I'), lambda v: (apply(rot('x',-r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('K'), lambda v: (apply(rot('x',+r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('J'), lambda v: (apply(rot('y',-r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('L'), lambda v: (apply(rot('y',+r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('U'), lambda v: (apply(rot('z',-r_step_deg)), redraw(v))[1])
    vis.register_key_callback(ord('O'), lambda v: (apply(rot('z',+r_step_deg)), redraw(v))[1])
    vis.register_key_callback(32, lambda v: (D.update(mat=np.eye(4)), redraw(v))[1])
    confirmed = {"ok": False}
    vis.register_key_callback(ord('Z'), lambda v: (confirmed.update(ok=True), v.close())[1])
    
    vis.run(); vis.destroy_window()
    return (D["mat"] @ T_init)

# =============================================================================
# ì„¹ì…˜ 1: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ê¸°ì¡´ í•¨ìˆ˜ë“¤, ìˆ˜ì • ì—†ìŒ)
# =============================================================================
def preprocess_pcd(pcd, fpfh_size):
    pcd_down = pcd.voxel_down_sample(fpfh_size)
    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=fpfh_size * 2, max_nn=30))
    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
        pcd_down, o3d.geometry.KDTreeSearchParamHybrid(radius=fpfh_size * 5, max_nn=100))
    return pcd_down, pcd_fpfh

def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, fpfh_size):
    distance_threshold = fpfh_size * 1.5
    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
        source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold,
        o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 3,
        [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.95),
         o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],
        o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.9999))
    return result

def refine_registration(source, target, initial_transform, fpfh_size):
    distance_threshold = fpfh_size * 0.4
    result = o3d.pipelines.registration.registration_icp(
        source, target, distance_threshold, initial_transform,
        o3d.pipelines.registration.TransformationEstimationPointToPlane())
    return result

# =============================================================================
# ì„¹ì…˜ 2: ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (â­ï¸â­ï¸â­ï¸ ìƒˆë¡œ ì¶”ê°€/ìˆ˜ì •ëœ ë¶€ë¶„ â­ï¸â­ï¸â­ï¸)
# =============================================================================
def load_all_scans_to_dataframe(file_paths):
    """
    ëª¨ë“  CSV íŒŒì¼ì„ í•˜ë‚˜ì˜ Pandas DataFrameìœ¼ë¡œ í†µí•© ë¡œë”©í•©ë‹ˆë‹¤.
    ì´ë•Œ, ìŠ¤ìºë„ˆì˜ í¸ì‹¬ íšŒì „ ì˜¤í”„ì…‹ì„ ë³´ì •í•˜ì—¬ ì¢Œí‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    all_dfs = []
    scanner_offset = 58.2  # í¸ì‹¬ íšŒì „ ì˜¤í”„ì…‹ ê°’ (mm)

    for i, path in enumerate(file_paths):
        try:
            df = pd.read_csv(path, header=None, names=['dist', 'az', 'el'])
            df['scanner_id'] = i  # ì–´ë–¤ ìŠ¤ìºë„ˆì—ì„œ ì™”ëŠ”ì§€ ID ë¶€ì—¬

            # az, el ìˆœìœ¼ë¡œ ì •ë ¬ (ë°ì´í„° ì²˜ë¦¬ ì¼ê´€ì„± ìœ ì§€)
            df_sorted = df.sort_values(by=['az', 'el']).copy()

            # ì •ë ¬ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 3D ì¢Œí‘œ ê³„ì‚°
            dist = df_sorted['dist'].values
            az_rad = np.radians(df_sorted['az'].values)
            el_rad = np.radians(df_sorted['el'].values + 90)

            # 1. ì¸¡ì • í—¤ë“œë¡œë¶€í„°ì˜ ìƒëŒ€ ì¢Œí‘œ
            x_relative = dist * np.cos(el_rad) * np.sin(az_rad)
            y_relative = dist * np.cos(el_rad) * np.cos(az_rad)
            z_relative = dist * np.sin(el_rad)

            # 2. Azimuth íšŒì „ì— ë”°ë¥¸ ì¸¡ì • í—¤ë“œì˜ ìœ„ì¹˜ (ì˜¤í”„ì…‹ ë³´ì •)
            scanner_x = scanner_offset * np.cos(az_rad)
            scanner_y = scanner_offset * np.sin(az_rad)
            # z_offsetì€ 0ìœ¼ë¡œ ê°€ì •

            # 3. ìµœì¢… ì¢Œí‘œ = ì¸¡ì • í—¤ë“œ ìœ„ì¹˜ + ìƒëŒ€ ì¢Œí‘œ
            df_sorted['x'] = + scanner_x + x_relative
            df_sorted['y'] = + scanner_y - y_relative
            df_sorted['z'] = z_relative
            
            all_dfs.append(df_sorted)
            print(f"-> '{os.path.basename(path)}' ë¡œë“œ ë° í¸ì‹¬ ë³´ì • ì™„ë£Œ, ìŠ¤ìºë„ˆ ID: {i}")

        except Exception as e:
            print(f"ì˜¤ë¥˜: '{path}' íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            
    # ëª¨ë“  DataFrameì„ í•˜ë‚˜ë¡œ í•©ì¹¨
    return pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()

def apply_transforms_to_dataframe(df, transforms):
    """ê³„ì‚°ëœ ë³€í™˜ í–‰ë ¬ì„ DataFrameì˜ ê° í¬ì¸íŠ¸ì— ì ìš©í•©ë‹ˆë‹¤."""
    df_transformed = df.copy()
    for scanner_id, transform in enumerate(transforms):
        if scanner_id == 0: continue
        indices = df_transformed[df_transformed['scanner_id'] == scanner_id].index
        points = df_transformed.loc[indices, ['x', 'y', 'z']].values
        points_h = np.hstack((points, np.ones((len(points), 1))))
        transformed_points_h = (transform @ points_h.T).T
        df_transformed.loc[indices, ['x', 'y', 'z']] = transformed_points_h[:, :3]
    print("-> ëª¨ë“  í¬ì¸íŠ¸ì— ë³€í™˜ í–‰ë ¬ ì ìš© ì™„ë£Œ.")
    return df_transformed

def optimal_voxel_partitioning(df, voxel_size):
    """
    Voxel ë‚´ í¬ì¸íŠ¸ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Owner Scannerì™€ Azimuth ì •ë³´ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    (transforms íŒŒë¼ë¯¸í„°ëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)
    """
    print("\n[3/4] Voxel ê¸°ë°˜ ê³µê°„ ë¶„í•  (ê°œì„ ëœ ë°©ì‹) ì‹œì‘...")
    
    # ê° í¬ì¸íŠ¸ê°€ ì–´ë–¤ Voxelì— ì†í•˜ëŠ”ì§€ ê³„ì‚°
    # ì´ ê³¼ì •ì€ ë²•ì„  ë²¡í„° ê³„ì‚°ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì•ìœ¼ë¡œ ì´ë™ ê°€ëŠ¥
    df['voxel_index'] = [tuple(idx) for idx in np.floor(df[['x', 'y', 'z']].values / voxel_size).astype(int)]
    
    # Voxelë³„ë¡œ í¬ì¸íŠ¸ ì¸ë±ìŠ¤ ê·¸ë£¹í™”
    voxel_to_points = df.groupby('voxel_index').groups
    print(f"-> {len(voxel_to_points)}ê°œì˜ ê³ ìœ  Voxel ìƒì„±ë¨.")

    results = []
    
    for voxel_index, point_indices in voxel_to_points.items():
        voxel_points_df = df.loc[point_indices]
        
        # Voxel ë‚´ì— í¬ì¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°
        if voxel_points_df.empty:
            continue
            
        # Voxel ë‚´ì—ì„œ ìŠ¤ìºë„ˆ IDë³„ë¡œ í¬ì¸íŠ¸ ê°œìˆ˜ë¥¼ ê³„ì‚°
        scanner_counts = voxel_points_df['scanner_id'].value_counts()
        
        # í¬ì¸íŠ¸ê°€ ê°€ì¥ ë§ì€ ìŠ¤ìºë„ˆë¥¼ Ownerë¡œ ê²°ì •
        best_scanner = scanner_counts.idxmax()
        
        # Owner ìŠ¤ìºë„ˆê°€ ìƒì„±í•œ í¬ì¸íŠ¸ë“¤ì˜ Azimuth ì •ë³´ ìˆ˜ì§‘
        owner_points_df = voxel_points_df[voxel_points_df['scanner_id'] == best_scanner]
        azimuths = sorted(owner_points_df['az'].unique().tolist())
        
        voxel_center = (np.array(voxel_index) + 0.5) * voxel_size
        results.append({
            'voxel_center_x': voxel_center[0], 
            'voxel_center_y': voxel_center[1], 
            'voxel_center_z': voxel_center[2],
            'owner_scanner_id': best_scanner, 
            'contributing_azimuths': str(azimuths)
        })
        
    print(f"-> {len(results)}ê°œ Voxelì˜ ì£¼ì¸ ê²°ì • ì™„ë£Œ.")
    return pd.DataFrame(results)
class StatisticalOutlierRemover:
    """
    Open3Dì˜ í†µê³„ì  ì´ìƒì¹˜ ì œê±°(statistical outlier removal) ê¸°ëŠ¥ì„
    ìº¡ìŠí™”í•œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

    ì´ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ í•„í„°ë§ íŒŒë¼ë¯¸í„°ë¥¼ ê°ì²´ì— ì €ì¥í•´ë‘ê³ 
    ì—¬ëŸ¬ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì— ì¼ê´€ë˜ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    def __init__(self, nb_neighbors, std_ratio):
        """
        í•„í„° ê°ì²´ë¥¼ ì´ˆê¸°í™”í•˜ê³  íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

        Args:
            nb_neighbors (int): ê° ì ì˜ í‰ê·  ê±°ë¦¬ë¥¼ ê³„ì‚°í•  ë•Œ ê³ ë ¤í•  ì´ì›ƒ ì ì˜ ìˆ˜.
            std_ratio (float): ì´ìƒì¹˜ë¡œ ê°„ì£¼í•  í‘œì¤€ í¸ì°¨ì˜ ë°°ìˆ˜.
                               ê°’ì´ ì‘ì„ìˆ˜ë¡ ë” ë§ì€ ì ì„ ì´ìƒì¹˜ë¡œ ì œê±°í•©ë‹ˆë‹¤.
        """
        self.nb_neighbors = nb_neighbors
        self.std_ratio = std_ratio
        print(f"í•„í„° ìƒì„±ë¨: ì´ì›ƒ ìˆ˜={self.nb_neighbors}, í‘œì¤€í¸ì°¨ ë¹„ìœ¨={self.std_ratio}")

    def filter(self, pcd):
        """
        ì…ë ¥ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì— ëŒ€í•´ í†µê³„ì  ì´ìƒì¹˜ ì œê±°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            pcd (o3d.geometry.PointCloud): í•„í„°ë§ì„ ì ìš©í•  í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ê°ì²´.

        Returns:
            tuple: (filtered_pcd, inlier_indices)
                - filtered_pcd (o3d.geometry.PointCloud): ì´ìƒì¹˜ê°€ ì œê±°ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ.
                - inlier_indices (o3d.utility.IntVector): ì›ë³¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œì—ì„œ ì‚´ì•„ë‚¨ì€ ì (inlier)ë“¤ì˜ ì¸ë±ìŠ¤.
        """
        if not isinstance(pcd, o3d.geometry.PointCloud):
            raise TypeError("ì…ë ¥ê°’ì€ open3d.geometry.PointCloud ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        print("ì´ìƒì¹˜ ì œê±° í•„í„°ë§ ì‹œì‘...")
        # remove_statistical_outlier í•¨ìˆ˜ëŠ” (í¬ì¸íŠ¸í´ë¼ìš°ë“œ, ì¸ë±ìŠ¤) íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        filtered_pcd, ind = pcd.remove_statistical_outlier(
            nb_neighbors=self.nb_neighbors,
            std_ratio=self.std_ratio
        )
        print(f"í•„í„°ë§ ì™„ë£Œ: ì›ë³¸ {len(pcd.points)}ê°œ -> ì œê±° í›„ {len(filtered_pcd.points)}ê°œ")
        return filtered_pcd, ind
# =============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€ (â­ï¸â­ï¸â­ï¸ ì´ìƒì¹˜ ì œê±° ë‹¨ê³„ ì¶”ê°€ â­ï¸â­ï¸â­ï¸)
# =============================================================================
if __name__ == "__main__":
    root = tk.Tk(); root.withdraw()
    print("ë¶„ì„í•  CSV íŒŒì¼ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì„ íƒí•˜ì„¸ìš” (2ê°œ ì´ìƒ)")
    file_paths = filedialog.askopenfilenames(title="CSV íŒŒì¼ ì„ íƒ (ê¸°ì¤€ íŒŒì¼ ë¨¼ì €)", filetypes=[("CSV Files", "*.csv")])

    if len(file_paths) < 2:
        print("íŒŒì¼ì´ 2ê°œ ë¯¸ë§Œ ì„ íƒë˜ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        # --- 1ë‹¨ê³„: ëª¨ë“  CSVë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë¡œë”© ---
        print("\n[1/5] CSV íŒŒì¼ ë¡œë”© ë° í†µí•©...")
        master_df = load_all_scans_to_dataframe(file_paths)
        if master_df.empty: exit()

        # --- â­ï¸ 2ë‹¨ê³„: ê° ìŠ¤ìº”ì— ëŒ€í•´ ì´ìƒì¹˜ ì œê±° ìˆ˜í–‰ (ìƒˆë¡œ ì¶”ê°€ëœ ë‹¨ê³„) â­ï¸ ---
        print("\n[2/5] í†µê³„ì  ì´ìƒì¹˜ ì œê±° ì‹œì‘...")
        # 1. ì´ìƒì¹˜ ì œê±° í•„í„° ê°ì²´ ìƒì„± (íŒŒë¼ë¯¸í„°ëŠ” ë°ì´í„°ì— ë§ê²Œ ì¡°ì •)
        sor_filter = StatisticalOutlierRemover(nb_neighbors=100, std_ratio=2.0)
        
        cleaned_dfs = []
        for i in range(len(file_paths)):
            scan_df = master_df[master_df['scanner_id'] == i]
            
            # DataFrameì„ Open3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¡œ ë³€í™˜
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(scan_df[['x', 'y', 'z']].values)
            
            # í•„í„° ì ìš©
            print(f"-> ìŠ¤ìºë„ˆ ID {i} í•„í„°ë§ ì¤‘...")
            filtered_pcd, inlier_indices = sor_filter.filter(pcd)
            
            # ì‚´ì•„ë‚¨ì€ ì¸ë±ìŠ¤(inlier_indices)ë¥¼ ì‚¬ìš©í•´ ì›ë³¸ DataFrame í•„í„°ë§
            # np.asarrayë¥¼ í†µí•´ o3d.utility.IntVectorë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
            cleaned_scan_df = scan_df.iloc[np.asarray(inlier_indices)]
            cleaned_dfs.append(cleaned_scan_df)

        # ê¹¨ë—í•´ì§„ DataFrameë“¤ì„ ë‹¤ì‹œ í•˜ë‚˜ë¡œ í•©ì¹¨
        master_df_cleaned = pd.concat(cleaned_dfs, ignore_index=True)
        print("âœ… ëª¨ë“  ìŠ¤ìº”ì˜ ì´ìƒì¹˜ ì œê±° ì™„ë£Œ.")


        # --- 3ë‹¨ê³„: ìë™ ì •í•©ì„ ìœ„í•œ ë³€í™˜ í–‰ë ¬ ê³„ì‚° (ê¸°ì¡´ 2ë‹¨ê³„) ---
        # â­ï¸ ì´ì œë¶€í„°ëŠ” ê¹¨ë—í•´ì§„ master_df_cleanedë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        print("\n[3/5] ì •í•© ë³€í™˜ í–‰ë ¬ ê³„ì‚° ì‹œì‘...")
        voxel_size = 300.0
        fpfh_size= 30
        
        pcds_for_reg = [o3d.geometry.PointCloud(o3d.utility.Vector3dVector(
            master_df_cleaned[master_df_cleaned['scanner_id'] == i][['x', 'y', 'z']].values
        )) for i in range(len(file_paths))]

        final_transforms = [np.identity(4)]
        target_pcd_merged = copy.deepcopy(pcds_for_reg[0])

        for i in range(1, len(pcds_for_reg)):
            source_pcd = pcds_for_reg[i]
            print(f"\n-> ìŠ¤ìº” {i} ('{os.path.basename(file_paths[i])}') ì •í•© ì¤‘...")
            
            source_down, source_fpfh = preprocess_pcd(source_pcd, fpfh_size)
            target_down, target_fpfh = preprocess_pcd(target_pcd_merged, fpfh_size)

            ransac_result = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, fpfh_size)
            
            print("\nğŸ‘€ RANSAC ê²°ê³¼ ê¸°ë°˜ ìˆ˜ë™ ë¯¸ì„¸ì¡°ì •: í‚¤ë³´ë“œë¡œ ì¡°ì • í›„ 'Z'ë¡œ í™•ì •!")
            
            # â­ï¸ current_source_dfë„ ê¹¨ë—í•œ ë°ì´í„°í”„ë ˆì„ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            current_source_df = master_df_cleaned[master_df_cleaned['scanner_id'] == i]
            
            T_tweaked = manual_tweak_registration( # í•¨ìˆ˜ ì´ë¦„ ë³€ê²½
                source_pcd, 
                target_pcd_merged, 
                ransac_result.transformation
            )
            
            target_pcd_merged.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=fpfh_size * 2, max_nn=30))
            icp_result = refine_registration(source_pcd, target_pcd_merged, T_tweaked, fpfh_size)
            
            final_transforms.append(icp_result.transformation)
            
            source_pcd.transform(icp_result.transformation)
            target_pcd_merged += source_pcd
        print("âœ… ëª¨ë“  ë³€í™˜ í–‰ë ¬ ê³„ì‚° ì™„ë£Œ.")

        # --- 3.5ë‹¨ê³„ -> 4ë‹¨ê³„: ë³€í™˜ í–‰ë ¬ ì ìš© ---
        print("\n[4/5] ë³€í™˜ í–‰ë ¬ ì ìš©...")
        # â­ï¸ ë³€í™˜ í–‰ë ¬ì€ ê¹¨ë—í•œ ë°ì´í„°í”„ë ˆì„ì— ì ìš©í•©ë‹ˆë‹¤.
        transformed_df = apply_transforms_to_dataframe(master_df_cleaned, final_transforms)

        # --- 4ë‹¨ê³„ -> 5ë‹¨ê³„: Voxel ê¸°ë°˜ ê³µê°„ ë¶„í•  ë° ì €ì¥/ì‹œê°í™” ---
        print("\n[5/5] Voxel ê¸°ë°˜ ê³µê°„ ë¶„í• , ì €ì¥ ë° ì‹œê°í™”...")
        results_df = optimal_voxel_partitioning(transformed_df, voxel_size)
        
        # (ì´í•˜ ì €ì¥ ë° ì‹œê°í™” ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼)
        output_dir = "final_voxel_results"
        if not os.path.exists(output_dir): os.makedirs(output_dir)
        output_filename = os.path.join(output_dir, "voxel_ownership_with_azimuth.csv")
        results_df.to_csv(output_filename, index=False)
        print(f"-> ìµœì¢… Voxel ê²°ê³¼ ì €ì¥ ì™„ë£Œ: '{output_filename}'")

        pcd_final = o3d.geometry.PointCloud()
        pcd_final.points = o3d.utility.Vector3dVector(transformed_df[['x', 'y', 'z']].values)
        
        voxel_owner_map = results_df.set_index(results_df.apply(
            lambda row: tuple(np.floor(row[['voxel_center_x', 'voxel_center_y', 'voxel_center_z']].values / voxel_size).astype(int)), axis=1
        ))['owner_scanner_id'].to_dict()

        point_colors = np.zeros_like(transformed_df[['x', 'y', 'z']].values)
        partition_colors = np.random.rand(len(file_paths), 3)
        
        owner_ids = transformed_df['voxel_index'].map(voxel_owner_map).fillna(-1).astype(int)
        valid_indices = owner_ids != -1
        point_colors[valid_indices] = partition_colors[owner_ids[valid_indices]]
        
        pcd_final.colors = o3d.utility.Vector3dVector(point_colors)
        
        o3d.visualization.draw_geometries([pcd_final], window_name="Voxel ê¸°ë°˜ ê³µê°„ ë¶„í•  ê²°ê³¼")
        
        print("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")